<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-01-12">

<title>impactfulai - Stable Diffusion Sampling Experiments</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">impactfulai</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Stable Diffusion Sampling Experiments</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 12, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>One of the great things with <em>Diffusion Models</em> (DMs) is that we can tune a bit their results without retraining them. Indeed, their inference process is somewhat an optimization process, and therefore can be tuned at several levels.</p>
<p>In this notebook, I try to analyze a bit the sampling process of <a href="https://huggingface.co/spaces/stabilityai/stable-diffusion">Stable Diffusion</a>, and derive from this analysis potential small variations (improvements?) of the images generated.</p>
<ins>
<p>Notes<ins>: 1. I do not go into details of how diffusion models work here, here are some amazing references for those of you who want to learn more about them: - <a href="https://yang-song.net/blog/2021/score/">A great blog post from Yang Song</a> (and the <a href="https://www.youtube.com/watch?v=nv-WTeKRLl0&amp;ab_channel=YingzhenLi">video</a> from the same author) - <a href="https://www.youtube.com/watch?t=2697&amp;v=_7rMfsA24Ls&amp;feature=youtu.be&amp;ab_channel=JeremyHoward">fastai part2 2022 lesson 9</a> - The paper <a href="https://arxiv.org/abs/2206.00364">“Elucidating the design space of diffusion models”</a> from Karras et. al., which gives an amazing unifying framework to reason about the different diffusion models</ins></p>
<ol start="2" type="1">
<li><p>Part of the text and code below are taken from this <a href="https://github.com/fastai/diffusion-nbs/blob/master/stable_diffusion.ipynb">fastai notebook</a>. Thanks to them for the amazing work done!</p></li>
<li><p>I did not put a high emphasis on code quality here, because I wanted to mostly focus on the ideas and intuitions to understand Stable Diffusion.</p></li>
</ol>
<section id="imports-and-utils" class="level2">
<h2 class="anchored" data-anchor-id="imports-and-utils">Imports And Utils</h2>
<p>To run Stable Diffusion on your computer you have to accept the model license. It’s an open CreativeML OpenRail-M license that claims no rights on the outputs you generate and prohibits you from deliberately producing illegal or harmful content. The <a href="https://huggingface.co/CompVis/stable-diffusion-v1-4">model card</a> provides more details. If you do accept the license, you need to be a registered user in 🤗 Hugging Face Hub and use an access token for the code to work. You have two options to provide your access token:</p>
<ul>
<li>Use the <code>huggingface-cli login</code> command-line tool in your terminal and paste your token when prompted. It will be saved in a file in your computer.</li>
<li>Or use <code>notebook_login()</code> in a notebook, which does the same thing.</li>
</ul>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install -Uq diffusers transformers fastcore</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.set_device(<span class="dv">1</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/seb.derhy/anaconda3/envs/sdv2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.<span class="bu">all</span> <span class="im">import</span> concat</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch, logging</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> notebook_login</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> diffusers <span class="im">import</span> StableDiffusionPipeline</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>logging.disable(logging.WARNING)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> (Path.home()<span class="op">/</span><span class="st">'.huggingface'</span><span class="op">/</span><span class="st">'token'</span>).exists(): notebook_login()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Very useful util function to display a grid of images</p>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_grid(imgs, rows, cols):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    w,h <span class="op">=</span> imgs[<span class="dv">0</span>].size</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> Image.new(<span class="st">'RGB'</span>, size<span class="op">=</span>(cols<span class="op">*</span>w, rows<span class="op">*</span>h))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, img <span class="kw">in</span> <span class="bu">enumerate</span>(imgs): grid.paste(img, box<span class="op">=</span>(i<span class="op">%</span>cols<span class="op">*</span>w, i<span class="op">//</span>cols<span class="op">*</span>h))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> grid</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="using-stable-diffusion" class="level2">
<h2 class="anchored" data-anchor-id="using-stable-diffusion">Using Stable Diffusion</h2>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">123</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">## From: https://mpost.io/best-100-stable-diffusion-prompts-the-most-beautiful-ai-text-to-image-prompts/ </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>prompts <span class="op">=</span> [</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'portrait photo of an astronaut riding a horse'</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'portrait photo of a handsome businesssman'</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'portrait photo of an asia old warrior chief, tribal panther make up, blue on red, side profile, looking away, serious eyes, 50mm portrait photography, hard rim lighting photography'</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'portrait photo headshot by mucha, sharp focus, elegant, render, octane, detailed, award winning photography, masterpiece, rim lit'</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>guidance_scale <span class="op">=</span> <span class="fl">7.5</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>num_inference_steps <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>num_images_per_prompt <span class="op">=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> diffusers <span class="im">import</span> StableDiffusionPipeline, EulerDiscreteScheduler</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>model_id <span class="op">=</span> <span class="st">"stabilityai/stable-diffusion-2-base"</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the Euler scheduler here instead</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> EulerDiscreteScheduler.from_pretrained(model_id, subfolder<span class="op">=</span><span class="st">"scheduler"</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> StableDiffusionPipeline.from_pretrained(model_id, scheduler<span class="op">=</span>scheduler, revision<span class="op">=</span><span class="st">"fp16"</span>, torch_dtype<span class="op">=</span>torch.float16)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> pipe.to(<span class="st">"cuda"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Fetching 12 files: 100%|██████████| 12/12 [00:00&lt;00:00, 4237.38it/s]</code></pre>
</div>
</div>
<p>Let’s start by running the pipeline “off-the-shelf”, without any modification</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> pipe(prompts, </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>             guidance_scale<span class="op">=</span>guidance_scale, </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>             num_inference_steps<span class="op">=</span>num_inference_steps, </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>             num_images_per_prompt<span class="op">=</span>num_images_per_prompt).images</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.11s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(images)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>4</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>ref_images <span class="op">=</span> images.copy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images, rows<span class="op">=</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="reproduce-inference-loop" class="level1">
<h1>Reproduce inference loop</h1>
<p>In order to customize the inference loop, the first step is to reimplement it, and add some “backdoors”. More specifically, we will add 2 backdoors: - One that allows for a different update at each iteration - One that allows for post-processing after the sampling loop has been run</p>
<p>These 2 customization points may look a bit random at this point, but we will see later how they can be useful</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> regular_update(latents, i, t, text_embeddings, do_classifier_free_guidance):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> torch.cat([latents] <span class="op">*</span> <span class="dv">2</span>) <span class="cf">if</span> do_classifier_free_guidance <span class="cf">else</span> latents</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> pipe.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict the noise residual</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> pipe.unet(latent_model_input, t, encoder_hidden_states<span class="op">=</span>text_embeddings).sample</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform guidance</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>        noise_pred_uncond, noise_pred_text <span class="op">=</span> noise_pred.chunk(<span class="dv">2</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred_uncond <span class="op">+</span> guidance_scale <span class="op">*</span> (noise_pred_text <span class="op">-</span> noise_pred_uncond)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    latents <span class="op">=</span> pipe.scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> my_sd_sampling(prompt<span class="op">=</span>prompts, device<span class="op">=</span>device, </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>             guidance_scale<span class="op">=</span>guidance_scale, </span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>             num_inference_steps<span class="op">=</span>num_inference_steps, </span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>             num_images_per_prompt<span class="op">=</span>num_images_per_prompt, </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>             custom_update<span class="op">=</span><span class="va">None</span>, post_processing<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 0. Default height and width to unet</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    height <span class="op">=</span> pipe.unet.config.sample_size <span class="op">*</span> pipe.vae_scale_factor</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> pipe.unet.config.sample_size <span class="op">*</span> pipe.vae_scale_factor</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. Check inputs. Raise error if not correct</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    pipe.check_inputs(prompt, height, width, callback_steps<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. Define call parameters</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> <span class="bu">isinstance</span>(prompt, <span class="bu">str</span>) <span class="cf">else</span> <span class="bu">len</span>(prompt)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># corresponds to doing no classifier free guidance.</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    do_classifier_free_guidance <span class="op">=</span> guidance_scale <span class="op">&gt;</span> <span class="fl">1.0</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3. Encode input prompt</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    text_embeddings <span class="op">=</span> pipe._encode_prompt(prompt, device, num_images_per_prompt, </span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>                                          do_classifier_free_guidance, negative_prompt<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 4. Prepare timesteps</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    pipe.scheduler.set_timesteps(num_inference_steps, device<span class="op">=</span>device)</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    timesteps <span class="op">=</span> pipe.scheduler.timesteps</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 5. Prepare latent variables</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    num_channels_latents <span class="op">=</span> pipe.unet.in_channels</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    latents <span class="op">=</span> pipe.prepare_latents(</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">*</span> num_images_per_prompt,</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>        num_channels_latents,</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>        height,</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        width,</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        text_embeddings.dtype,</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>        device,</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>        generator<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>        latents<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>    num_warmup_steps <span class="op">=</span> <span class="bu">len</span>(timesteps) <span class="op">-</span> num_inference_steps <span class="op">*</span> pipe.scheduler.order</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 7. Denoising loop</span></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(pipe.progress_bar(timesteps)):</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> custom_update:</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>            latents <span class="op">=</span> custom_update(latents, i, t, text_embeddings, do_classifier_free_guidance)</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>            latents <span class="op">=</span> regular_update(latents, i, t, text_embeddings, do_classifier_free_guidance)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> post_processing: <span class="co">## We are adding here the option of post-processing the final latent outputs</span></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        latents <span class="op">=</span> post_processing(<span class="op">**</span>kwargs)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 8. Post-processing</span></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> pipe.decode_latents(latents)</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 9. Run safety checker</span></span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>    image, has_nsfw_concept <span class="op">=</span> pipe.run_safety_checker(image, device, text_embeddings.dtype)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 10. Convert to PIL</span></span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> pipe.numpy_to_pil(image)</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> images</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.11s/it]</code></pre>
</div>
</div>
<p>Let’s check that our pipeline gives the same results as the original one</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> np.<span class="bu">sum</span>(np.array(imgs[<span class="dv">0</span>])<span class="op">-</span>np.array(ref_images[<span class="dv">0</span>]))<span class="op">==</span><span class="dv">0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># image_grid(ref_images + imgs, rows=2*num_images_per_prompt, cols=len(prompts))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="log-and-analyze-noise-predictions" class="level1">
<h1>Log and analyze noise predictions</h1>
<p>Below, we are going to log the 3 noise predictions that are performed at each timestep: - <code>noise_pred_uncond</code> (with just the noisy image as input) - <code>noise_pred_text</code> (with the noisy image + text encoding as input) - <code>noise_pred</code> (weighted average between them using the guidance_scale parameter)</p>
<section id="log-the-noise-predictions" class="level2">
<h2 class="anchored" data-anchor-id="log-the-noise-predictions">Log the noise predictions</h2>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_with_debug_logs(latents, i, t, text_embeddings, do_classifier_free_guidance):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> torch.cat([latents] <span class="op">*</span> <span class="dv">2</span>) <span class="cf">if</span> do_classifier_free_guidance <span class="cf">else</span> latents</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> pipe.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict the noise residual</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> pipe.unet(latent_model_input, t, encoder_hidden_states<span class="op">=</span>text_embeddings).sample</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform guidance</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        noise_pred_uncond, noise_pred_text <span class="op">=</span> noise_pred.chunk(<span class="dv">2</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        noise_unconds.append(noise_pred_uncond.detach().cpu()) <span class="co">## Log the noise unconds results</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        noise_conds.append(noise_pred_text.detach().cpu()) <span class="co">## Log the noise conds results</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred_uncond <span class="op">+</span> guidance_scale <span class="op">*</span> (noise_pred_text <span class="op">-</span> noise_pred_uncond)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        noise_preds.append(noise_pred.detach().cpu())</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    new_latents <span class="op">=</span> pipe.scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    latent_step <span class="op">=</span> new_latents<span class="op">-</span>latents </span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>noise_preds, noise_unconds, noise_conds <span class="op">=</span> [], [], []</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_debug_logs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> np.<span class="bu">sum</span>(np.array(imgs[<span class="dv">0</span>])<span class="op">-</span>np.array(ref_images[<span class="dv">0</span>]))<span class="op">==</span><span class="dv">0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># image_grid(ref_images[:len(prompts)] + imgs[:len(prompts)] </span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co">#            + ref_images[len(prompts):] + imgs[len(prompts):], rows=2*num_images_per_prompt, cols=len(prompts))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="compare-the-noise-norms" class="level2">
<h2 class="anchored" data-anchor-id="compare-the-noise-norms">Compare the noise norms</h2>
<p>One thing we observe from the code above (<code>noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)</code>) is that we actually pass the input image twice to the network at each iteration:</p>
<ul>
<li>Once <em>without</em> the conditional text input -&gt; Predict the noise from the noisy image only</li>
<li>Once <em>with</em> the conditional text input -&gt; Predict the noise from the noisy image AND the image description’s encoding</li>
</ul>
<p>Since these inputs are a bit different, we expect these 2 passes to predict different noise values (i.e.&nbsp;point towards different real images). However, since both networks are trained to predict noise from a noisy image, we should expect the noise prediction to have approximately the same norm in both cases.</p>
<p>Let’s see if this is true, and let’s also compare this norm with the final noise prediction norm.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>noise_preds_norm <span class="op">=</span> [pred.norm() <span class="cf">for</span> pred <span class="kw">in</span> noise_preds]</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>noise_unconds_norm <span class="op">=</span> [pred.norm() <span class="cf">for</span> pred <span class="kw">in</span> noise_unconds]</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>noise_conds_norm <span class="op">=</span> [pred.norm() <span class="cf">for</span> pred <span class="kw">in</span> noise_conds]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(<span class="bu">range</span>(num_inference_steps), noise_unconds_norm, c<span class="op">=</span><span class="st">'b'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">"Unconditional noise pred norm"</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(<span class="bu">range</span>(num_inference_steps), noise_conds_norm, c<span class="op">=</span><span class="st">'g'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">"Conditional noise pred norm"</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(<span class="bu">range</span>(num_inference_steps), noise_preds_norm, c<span class="op">=</span><span class="st">'r'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">"Final noise pred norm"</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>&lt;matplotlib.legend.Legend at 0x7f5ab3fd3670&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-25-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Here we indeed see that the unconditional and conditional noise norms are approximately the same. However, the final noise prediction seems to have a slightly different norm? Why is that?</p>
<p>The answer to this question is in the next line of code:</p>
<p><code>noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)</code></p>
<p>This line does a weighted average between the conditioned and unconditioned noise prediction, and has therefore ABSOLUTELY NO REASON to have the same norm.</p>
<p>Does this make sense? Well… In my opinion, not so much, so let’s try to re-normalize things :).</p>
</section>
</section>
<section id="improve-the-pipeline-with-whole-rescale" class="level1">
<h1>Improve the pipeline with “whole” rescale</h1>
<p>NOTE: the idea implemented below was first suggested by <a href="https://twitter.com/jeremyphoward">Jeremy Howard</a> in this <a href="https://twitter.com/jeremyphoward/status/1584667612348227584?s=20&amp;t=40IVYJnW8kpdCHbNJYUZWw">Twitter thread</a></p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_with_rescale(latents, i, t, text_embeddings, do_classifier_free_guidance):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> torch.cat([latents] <span class="op">*</span> <span class="dv">2</span>) <span class="cf">if</span> do_classifier_free_guidance <span class="cf">else</span> latents</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> pipe.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict the noise residual</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> pipe.unet(latent_model_input, t, encoder_hidden_states<span class="op">=</span>text_embeddings).sample</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform guidance</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>        noise_pred_uncond, noise_pred_text <span class="op">=</span> noise_pred.chunk(<span class="dv">2</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred_uncond <span class="op">+</span> guidance_scale <span class="op">*</span> (noise_pred_text <span class="op">-</span> noise_pred_uncond)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred<span class="op">/</span>noise_pred.norm()<span class="op">*</span>noise_pred_uncond.norm() <span class="co">### THIS IS THE KEY CHANGE</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    latents <span class="op">=</span> pipe.scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_rescale)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images[:<span class="bu">len</span>(prompts)] <span class="op">+</span> imgs[:<span class="bu">len</span>(prompts)] </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> ref_images[<span class="bu">len</span>(prompts):] <span class="op">+</span> imgs[<span class="bu">len</span>(prompts):], rows<span class="op">=</span><span class="dv">2</span><span class="op">*</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-30-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-32-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Definitely improves the image quality in my opinion!</p>
</section>
<section id="log-and-analyze-latent-space-trajectory" class="level1">
<h1>Log and analyze latent space trajectory</h1>
<section id="log-trajectory" class="level2">
<h2 class="anchored" data-anchor-id="log-trajectory">Log trajectory</h2>
<p>Below, we are going to log the trajectory point at each timestep, so that we can analyze a bit what’s happening</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_with_debug_logs(latents, i, t, text_embeddings, do_classifier_free_guidance):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> torch.cat([latents] <span class="op">*</span> <span class="dv">2</span>) <span class="cf">if</span> do_classifier_free_guidance <span class="cf">else</span> latents</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> pipe.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict the noise residual</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> pipe.unet(latent_model_input, t, encoder_hidden_states<span class="op">=</span>text_embeddings).sample</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform guidance</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>        noise_pred_uncond, noise_pred_text <span class="op">=</span> noise_pred.chunk(<span class="dv">2</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred_uncond <span class="op">+</span> guidance_scale <span class="op">*</span> (noise_pred_text <span class="op">-</span> noise_pred_uncond)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    new_latents <span class="op">=</span> pipe.scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>    latent_step <span class="op">=</span> new_latents<span class="op">-</span>latents </span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># THIS IS THE IMPORTANT LINES --&gt; Log information</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>    traj_pts_times.append(t.detach().cpu())</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    traj_pts_values.append(new_latents.detach().cpu())</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times, traj_pts_values <span class="op">=</span> [], []</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_debug_logs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<p>I find the fact that time is moving backward a bit unintuitive, especially for the kind of things we’ll do next, so let’s reverse it.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>[tensor(999., dtype=torch.float64),
 tensor(978.6122, dtype=torch.float64),
 tensor(958.2245, dtype=torch.float64),
 tensor(937.8367, dtype=torch.float64),
 tensor(917.4490, dtype=torch.float64),
 tensor(897.0612, dtype=torch.float64),
 tensor(876.6735, dtype=torch.float64),
 tensor(856.2857, dtype=torch.float64),
 tensor(835.8980, dtype=torch.float64),
 tensor(815.5102, dtype=torch.float64)]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times <span class="op">=</span> [<span class="dv">999</span><span class="op">-</span>t <span class="cf">for</span> t <span class="kw">in</span> traj_pts_times]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualize-the-trajectory-using-dimension-reduction" class="level2">
<h2 class="anchored" data-anchor-id="visualize-the-trajectory-using-dimension-reduction">Visualize the trajectory using dimension reduction</h2>
<p>Here we will perform 3 different types of dimension reduction in order to visualize the trajectory - <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">T-SNE</a> - <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a> - <a href="https://en.wikipedia.org/wiki/Multidimensional_scaling">MDS</a></p>
<p>In these plot, yellow represent the enf of the sampling process, while the purple represents the beginning of the sampling process.</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> TSNE</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.stack(traj_pts_values).view(<span class="bu">len</span>(traj_pts_values), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>X.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>torch.Size([50, 65536])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>X_lowdim <span class="op">=</span> TSNE(n_components<span class="op">=</span><span class="dv">2</span>, learning_rate<span class="op">=</span><span class="st">'auto'</span>, init<span class="op">=</span><span class="st">'random'</span>, perplexity<span class="op">=</span><span class="dv">3</span>).fit_transform(X)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>X_lowdim.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>(50, 2)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_lowdim[:, <span class="dv">0</span>], X_lowdim[:, <span class="dv">1</span>], c<span class="op">=</span>traj_pts_times)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7f5ab3eca730&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-39-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>X_lowdim <span class="op">=</span> pca.fit_transform(X)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>X_lowdim.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>(50, 2)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_lowdim[:, <span class="dv">0</span>], X_lowdim[:, <span class="dv">1</span>], c<span class="op">=</span>traj_pts_times)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7f5aaaaf7fa0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-41-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>I personally really like the MDS representation, because it tries to project the data in a way that best preserves distances.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.manifold <span class="im">import</span> MDS</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>mds <span class="op">=</span> MDS()</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>X_lowdim <span class="op">=</span> mds.fit_transform(X)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>X_lowdim.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>(50, 2)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(X_lowdim[:, <span class="dv">0</span>], X_lowdim[:, <span class="dv">1</span>], c<span class="op">=</span>traj_pts_times)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7f5aaaa729d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-43-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We can see that the trajectory is quite smooth!! This is something we’ll try to leverage later on. But first let’s do some more analysis:</p>
</section>
<section id="analyze-the-steps-length-and-directions" class="level2">
<h2 class="anchored" data-anchor-id="analyze-the-steps-length-and-directions">Analyze the steps length and directions</h2>
<p>One interesting way to analyze the trajectory is to look at each step performed in the sampling loop: - How big was the step? - How much is it changing direction in the course of sampling?</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>steps <span class="op">=</span> [(traj_pts_values[i<span class="op">+</span><span class="dv">1</span>]<span class="op">-</span>traj_pts_values[i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(traj_pts_values)<span class="op">-</span><span class="dv">1</span>)]</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>steps_norms <span class="op">=</span> [step.norm() <span class="cf">for</span> step <span class="kw">in</span> steps]</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>steps_unit_vecs <span class="op">=</span> [step<span class="op">/</span>step.norm() <span class="cf">for</span> step <span class="kw">in</span> steps]</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>steps_dir_change <span class="op">=</span> [(steps_unit_vecs[i<span class="op">+</span><span class="dv">1</span>]<span class="op">-</span>steps_unit_vecs[i]).norm() <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(steps_unit_vecs)<span class="op">-</span><span class="dv">1</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">12</span>))</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].scatter(traj_pts_times[<span class="dv">2</span>:], steps_dir_change)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">"Direction Changes Strength"</span>)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].scatter(traj_pts_times[<span class="dv">1</span>:], steps_norms)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">"Step Length"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>Text(0.5, 1.0, 'Step Length')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-45-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Interestingly, we see that the direction is changing a lot at the end. This tends to make me think that the algorithm overshoots somehow at the end. Let’s try to fix this!</p>
</section>
</section>
<section id="prevent-overshooting-at-the-end" class="level1">
<h1>Prevent overshooting at the end</h1>
<p>One very simple way to prevent this convergence overshooting at the end is to only do “part of the way”. That is, if the noise prediction says you should do a step size of x, you actually do a step of alpha*x, where alpha&lt;1. Let’s try to implement something like this</p>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_without_overshoot(latents, i, t, text_embeddings, do_classifier_free_guidance):    </span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> torch.cat([latents] <span class="op">*</span> <span class="dv">2</span>) <span class="cf">if</span> do_classifier_free_guidance <span class="cf">else</span> latents</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> pipe.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict the noise residual</span></span>
<span id="cb63-7"><a href="#cb63-7" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> pipe.unet(latent_model_input, t, encoder_hidden_states<span class="op">=</span>text_embeddings).sample</span>
<span id="cb63-8"><a href="#cb63-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-9"><a href="#cb63-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform guidance</span></span>
<span id="cb63-10"><a href="#cb63-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb63-11"><a href="#cb63-11" aria-hidden="true" tabindex="-1"></a>        noise_pred_uncond, noise_pred_text <span class="op">=</span> noise_pred.chunk(<span class="dv">2</span>)</span>
<span id="cb63-12"><a href="#cb63-12" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred_uncond <span class="op">+</span> guidance_scale <span class="op">*</span> (noise_pred_text <span class="op">-</span> noise_pred_uncond)</span>
<span id="cb63-13"><a href="#cb63-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-14"><a href="#cb63-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span id="cb63-15"><a href="#cb63-15" aria-hidden="true" tabindex="-1"></a>    new_latents <span class="op">=</span> pipe.scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb63-16"><a href="#cb63-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-17"><a href="#cb63-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">## THIS IS THE IMPORTANT CHANGE</span></span>
<span id="cb63-18"><a href="#cb63-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i<span class="op">&gt;=</span><span class="bu">round</span>(<span class="fl">0.8</span><span class="op">*</span>num_inference_steps) <span class="kw">and</span> i<span class="op">!=</span>num_inference_steps<span class="op">-</span><span class="dv">1</span>: <span class="co">## When we get towards the end of the sampling </span></span>
<span id="cb63-19"><a href="#cb63-19" aria-hidden="true" tabindex="-1"></a>        new_latents <span class="op">=</span> latents <span class="op">+</span> <span class="fl">0.85</span> <span class="op">*</span> (new_latents<span class="op">-</span>latents) <span class="co">#do only 85% of the step supposed to be done.</span></span>
<span id="cb63-20"><a href="#cb63-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>steps_unit_vecs <span class="op">=</span> []</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>steps_magnitudes <span class="op">=</span> []</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_without_overshoot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images[:<span class="bu">len</span>(prompts)] <span class="op">+</span> imgs[:<span class="bu">len</span>(prompts)] </span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> ref_images[<span class="bu">len</span>(prompts):] <span class="op">+</span> imgs[<span class="bu">len</span>(prompts):], rows<span class="op">=</span><span class="dv">2</span><span class="op">*</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-49-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can do a before/after comparison for one of the images</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="op">-</span><span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-50-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="op">-</span><span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-51-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The images look definitely sharper, but also a bit noisier unfortunately.</p>
</section>
<section id="trajectory-predict" class="level1">
<h1>Trajectory predict</h1>
<p>As we saw in the trajectory analysis, the sampling process seems to follow a relatively smooth curve, but the convergence kind of seems “unfinished”. So one natural idea would be to regress this trajectory with a polynomial, and then evaluate it at a later time in order to see what the results would have been after a few more iterations (which we don’t want to do because we want to maintain the same computational budget).</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_with_debug_logs(latents, i, t, text_embeddings, do_classifier_free_guidance):</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> torch.cat([latents] <span class="op">*</span> <span class="dv">2</span>) <span class="cf">if</span> do_classifier_free_guidance <span class="cf">else</span> latents</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> pipe.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict the noise residual</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> pipe.unet(latent_model_input, t, encoder_hidden_states<span class="op">=</span>text_embeddings).sample</span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform guidance</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>        noise_pred_uncond, noise_pred_text <span class="op">=</span> noise_pred.chunk(<span class="dv">2</span>)</span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred_uncond <span class="op">+</span> guidance_scale <span class="op">*</span> (noise_pred_text <span class="op">-</span> noise_pred_uncond)</span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>    new_latents <span class="op">=</span> pipe.scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb70-16"><a href="#cb70-16" aria-hidden="true" tabindex="-1"></a>    latent_step <span class="op">=</span> new_latents<span class="op">-</span>latents </span>
<span id="cb70-17"><a href="#cb70-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-18"><a href="#cb70-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Only change we do here in the update is logging the trajectory</span></span>
<span id="cb70-19"><a href="#cb70-19" aria-hidden="true" tabindex="-1"></a>    traj_pts_times.append(t.detach().cpu())</span>
<span id="cb70-20"><a href="#cb70-20" aria-hidden="true" tabindex="-1"></a>    traj_pts_values.append(new_latents.detach().cpu())</span>
<span id="cb70-21"><a href="#cb70-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This time, we are going to define and use the post-processing function</p>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_converged_latent(i_start<span class="op">=</span><span class="dv">0</span>, deg<span class="op">=</span><span class="dv">5</span>, eval_time<span class="op">=</span><span class="dv">999</span>):</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    bs <span class="op">=</span> traj_pts_values[<span class="dv">0</span>].shape[<span class="dv">0</span>]</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>    pts <span class="op">=</span> torch.stack([pt.flatten() <span class="cf">for</span> pt <span class="kw">in</span> traj_pts_values])</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    times <span class="op">=</span> torch.Tensor([t <span class="cf">for</span> t <span class="kw">in</span> traj_pts_times])</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    times <span class="op">=</span> <span class="dv">999</span><span class="op">-</span>times <span class="co"># We reverse time as previously</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>    coefficients, residuals, rank, singular_values, rcond <span class="op">=</span> np.polyfit(times.<span class="bu">float</span>().detach().cpu().numpy()[i_start:], </span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>                                                                   pts.<span class="bu">float</span>().detach().cpu().numpy()[i_start:], </span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>                                                                   deg<span class="op">=</span>deg, full<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.polyval(coefficients, eval_time)</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    converged_latents <span class="op">=</span> torch.from_numpy(y_pred).view(bs, <span class="dv">4</span>, <span class="dv">64</span>, <span class="dv">64</span>).half().to(device)</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> converged_latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times, traj_pts_values <span class="op">=</span> [], []</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_debug_logs, post_processing<span class="op">=</span>compute_converged_latent, </span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>                      i_start<span class="op">=</span><span class="dv">0</span>, deg<span class="op">=</span><span class="dv">6</span>, eval_time<span class="op">=</span><span class="dv">1024</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images[:<span class="bu">len</span>(prompts)] <span class="op">+</span> imgs[:<span class="bu">len</span>(prompts)] </span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> ref_images[<span class="bu">len</span>(prompts):] <span class="op">+</span> imgs[<span class="bu">len</span>(prompts):], rows<span class="op">=</span><span class="dv">2</span><span class="op">*</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-55-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-56-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-57-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Interestingly, this seems to have mostly an effect on the lighting. Let’s try to play a bit with the parameters</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times, traj_pts_values <span class="op">=</span> [], []</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_debug_logs, post_processing<span class="op">=</span>compute_converged_latent, </span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>                      i_start<span class="op">=</span><span class="dv">0</span>, deg<span class="op">=</span><span class="dv">6</span>, eval_time<span class="op">=</span><span class="dv">1100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images[:<span class="bu">len</span>(prompts)] <span class="op">+</span> imgs[:<span class="bu">len</span>(prompts)] </span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> ref_images[<span class="bu">len</span>(prompts):] <span class="op">+</span> imgs[<span class="bu">len</span>(prompts):], rows<span class="op">=</span><span class="dv">2</span><span class="op">*</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-59-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times, traj_pts_values <span class="op">=</span> [], []</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_debug_logs, post_processing<span class="op">=</span>compute_converged_latent, </span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>                      i_start<span class="op">=</span><span class="dv">0</span>, deg<span class="op">=</span><span class="dv">5</span>, eval_time<span class="op">=</span><span class="dv">1050</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images[:<span class="bu">len</span>(prompts)] <span class="op">+</span> imgs[:<span class="bu">len</span>(prompts)] </span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> ref_images[<span class="bu">len</span>(prompts):] <span class="op">+</span> imgs[<span class="bu">len</span>(prompts):], rows<span class="op">=</span><span class="dv">2</span><span class="op">*</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-61-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times, traj_pts_values <span class="op">=</span> [], []</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_debug_logs, post_processing<span class="op">=</span>compute_converged_latent, </span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>                      i_start<span class="op">=</span><span class="dv">0</span>, deg<span class="op">=</span><span class="dv">4</span>, eval_time<span class="op">=</span><span class="dv">1050</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images[:<span class="bu">len</span>(prompts)] <span class="op">+</span> imgs[:<span class="bu">len</span>(prompts)] </span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> ref_images[<span class="bu">len</span>(prompts):] <span class="op">+</span> imgs[<span class="bu">len</span>(prompts):], rows<span class="op">=</span><span class="dv">2</span><span class="op">*</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-63-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Ok, not exactly what we were expecting… This means that this polynomial fit technique is probably not very robust. But maybe it can be used as a new cool form of AI-generated art?</p>
</section>
<section id="everything-combined" class="level1">
<h1>Everything combined</h1>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_with_all_improv(latents, i, t, text_embeddings, do_classifier_free_guidance):</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> torch.cat([latents] <span class="op">*</span> <span class="dv">2</span>) <span class="cf">if</span> do_classifier_free_guidance <span class="cf">else</span> latents</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    latent_model_input <span class="op">=</span> pipe.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># predict the noise residual</span></span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    noise_pred <span class="op">=</span> pipe.unet(latent_model_input, t, encoder_hidden_states<span class="op">=</span>text_embeddings).sample</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># perform guidance</span></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> do_classifier_free_guidance:</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>        noise_pred_uncond, noise_pred_text <span class="op">=</span> noise_pred.chunk(<span class="dv">2</span>)</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>        dir_change <span class="op">=</span> noise_pred_text<span class="op">/</span>noise_pred_text.norm() <span class="op">-</span> noise_pred_uncond<span class="op">/</span>noise_pred_uncond.norm()</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred_uncond <span class="op">+</span> guidance_scale <span class="op">*</span> dir_change <span class="op">*</span> noise_pred_uncond.norm()</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> noise_pred<span class="op">/</span>noise_pred.norm()<span class="op">*</span>noise_pred_uncond.norm()</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the previous noisy sample x_t -&gt; x_t-1</span></span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>    new_latents <span class="op">=</span> pipe.scheduler.step(noise_pred, t, latents).prev_sample</span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i<span class="op">&gt;=</span><span class="bu">round</span>(<span class="fl">0.8</span><span class="op">*</span>num_inference_steps) <span class="kw">and</span> i<span class="op">!=</span>num_inference_steps<span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a>        new_latents <span class="op">=</span> latents <span class="op">+</span> <span class="fl">0.9</span> <span class="op">*</span> (new_latents<span class="op">-</span>latents)</span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb86-21"><a href="#cb86-21" aria-hidden="true" tabindex="-1"></a>    latent_step <span class="op">=</span> new_latents<span class="op">-</span>latents </span>
<span id="cb86-22"><a href="#cb86-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb86-23"><a href="#cb86-23" aria-hidden="true" tabindex="-1"></a>    traj_pts_times.append(t.detach().cpu())</span>
<span id="cb86-24"><a href="#cb86-24" aria-hidden="true" tabindex="-1"></a>    traj_pts_values.append(new_latents.detach().cpu())</span>
<span id="cb86-25"><a href="#cb86-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> new_latents</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>traj_pts_times, traj_pts_values <span class="op">=</span> [], []</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> my_sd_sampling(custom_update<span class="op">=</span>update_with_all_improv, post_processing<span class="op">=</span>compute_converged_latent, </span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>                      i_start<span class="op">=</span><span class="dv">0</span>, deg<span class="op">=</span><span class="dv">6</span>, eval_time<span class="op">=</span><span class="dv">1024</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:55&lt;00:00,  1.12s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>image_grid(ref_images[:<span class="bu">len</span>(prompts)] <span class="op">+</span> imgs[:<span class="bu">len</span>(prompts)] </span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>           <span class="op">+</span> ref_images[<span class="bu">len</span>(prompts):] <span class="op">+</span> imgs[<span class="bu">len</span>(prompts):], rows<span class="op">=</span><span class="dv">2</span><span class="op">*</span>num_images_per_prompt, cols<span class="op">=</span><span class="bu">len</span>(prompts))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-66-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-67-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-68-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-69-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-70-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-71-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-72-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>ref_images[<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-73-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>imgs[<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<p><img src="2022-25-12-Stable-Diffusion-Sampling-Analysis_files/figure-html/cell-74-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In this notebook, we made 3 modifications: - rescale during the guidance weighted average - preventing the overshoot at the end - smoothing the sampling trajectory using polynomial fit</p>
<p>Each of those modifications gave slightly different results taken independently. When combined together, they make the images MUCH sharper, which can be a good or bad thing, depending on the effect one wants to get at the end.</p>
<p>At the end of the day, I think the main takeaway is that understanding and controling the sampling process of diffusion models can have a very important impact, and understanding it can be crucial.</p>


</section>

</ins></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>